{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0523 04:14:18.648649 140664790570752 deprecation_wrapper.py:119] From /home/rick/Xi/WordEmbeddingEval/SentEval-master-new/official/transformer/model/attention_layer.py:24: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "W0523 04:14:18.669373 140664790570752 deprecation_wrapper.py:119] From /home/rick/Xi/WordEmbeddingEval/SentEval-master-new/CNN_Model.py:73: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "W0523 04:14:18.706784 140664790570752 deprecation_wrapper.py:119] From /home/rick/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:54: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0523 04:14:18.710404 140664790570752 deprecation_wrapper.py:119] From /home/rick/anaconda3/lib/python3.6/site-packages/tensorflow_hub/__init__.py:65: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "import numpy as np \n",
    "import senteval\n",
    "import copy\n",
    "import operator\n",
    "import torch\n",
    "import CNN_Model\n",
    "PATH_SENTEVAL = '../'\n",
    "PATH_TO_DATA = 'data'\n",
    "\n",
    "import embedding\n",
    "\n",
    "model = None \n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentenceList = []\n",
    "    \n",
    "#     for i,sent in enumerate(batch):\n",
    "#         if len(sent) == 0:\n",
    "#             batch[i] = ['</p>']\n",
    "    \n",
    "#     if params['embed'] == 'Glove':\n",
    "#         sentences = batch\n",
    "#     else:\n",
    "#         sentences = [' '.join(s) for s in batch]\n",
    "  \n",
    "#     if params['embed'] == 'Glove':\n",
    "#         output,_ = embedding.getGloveEmb(sentences)\n",
    "#     if params['embed'] == 'ELMO':\n",
    "#         output,_ = embedding.getElmoEmb(sentences)\n",
    "#     if params['embed'] == 'GPT2':\n",
    "#         output,_ = embedding.getGPT2Emb(sentences)\n",
    "#         print(output.shape,output[0].shape)\n",
    "#     if params['embed'] == 'BERT':\n",
    "#         output,_ = embedding.getBertEmb(sentences)\n",
    "#     print(output.shape)\n",
    "#     global x \n",
    "#     x = output\n",
    "#     for embed in output:\n",
    "\n",
    "#         maxPool = embed.max(axis = 0,keepdims = True)\n",
    "#         meanPool = embed.mean(axis = 0,keepdims = True)\n",
    "#         vec = list(maxPool[0]) + list(meanPool[0])\n",
    "#         sentenceList.append(vec)\n",
    "      \n",
    "#     sentenceList = np.array(sentenceList)\n",
    "#     print(sentenceList.shape)\n",
    "#     return sentenceList\n",
    "\n",
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentenceList = []\n",
    "    \n",
    "    for i,sent in enumerate(batch):\n",
    "        if len(sent) == 0:\n",
    "            batch[i] = ['</p>']\n",
    "    \n",
    "    if params['embed'] == 'Glove':\n",
    "        sentences = batch\n",
    "    else:\n",
    "        sentences = [' '.join(s) for s in batch]\n",
    "        \n",
    "  \n",
    "    if params['embed'] == 'Glove':\n",
    "        output,_ = embedding.getGloveEmb(sentences)\n",
    "        output_temp = []\n",
    "        for i in output:\n",
    "            tem = np.float32([i])\n",
    "            output_temp.append(CNN_Model.getTransformer(params,tem))\n",
    "        output = output_temp\n",
    "        \n",
    "    if params['embed'] == 'ELMO':\n",
    "        output,_ = embedding.getElmoEmb(sentences)\n",
    "        output = np.float32(output)\n",
    "        \n",
    "        output = CNN_Model.getTransformer(params,output)\n",
    "#         output_temp = []\n",
    "#         for i in output:\n",
    "#             tem = np.float32([i])\n",
    "#             output_temp.append(CNN_Model.getTransformer(params,tem))\n",
    "#         output = output_temp\n",
    "        \n",
    "        \n",
    "    if params['embed'] == 'GPT2':\n",
    "        output,length = embedding.getGPT2Emb(sentences,True,-1)\n",
    "        output = np.float32(output)\n",
    "        \n",
    "        output = CNN_Model.getTransformer(params,output)\n",
    "        \n",
    "        output_temp = []\n",
    "\n",
    "        for index,sent in enumerate(output):\n",
    "            \n",
    "            output_temp.append(sent[:length[index]])\n",
    "        output = output_temp\n",
    "        \n",
    "    if params['embed'] == 'BERT':\n",
    "        output,_ = embedding.getBertEmb(sentences)\n",
    "        output_temp = []\n",
    "        for i in output:\n",
    "            tem = np.float32([i])\n",
    "            output_temp.append(CNN_Model.getTransformer(params,tem))\n",
    "        output = output_temp\n",
    "\n",
    "    global x \n",
    "    x = output\n",
    "    for embed in output:\n",
    "        maxPool = embed.max(axis = 0,keepdims = True)\n",
    "        meanPool = embed.mean(axis = 0,keepdims = True)\n",
    "        vec = list(maxPool[0]) + list(meanPool[0])\n",
    "        sentenceList.append(vec)\n",
    "      \n",
    "    sentenceList = np.array(sentenceList)\n",
    "    print(sentenceList.shape)\n",
    "    return sentenceList\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(63, 1536)\n",
      "{'CR': {'devacc': 76.21, 'acc': 75.44, 'ndev': 3775, 'ntest': 3775}}\n",
      "MR\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(38, 1536)\n",
      "{'MR': {'devacc': 75.45, 'acc': 74.4, 'ndev': 10662, 'ntest': 10662}}\n",
      "MPQA\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(110, 1536)\n",
      "{'MPQA': {'devacc': 82.53, 'acc': 82.07, 'ndev': 10606, 'ntest': 10606}}\n",
      "SUBJ\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(16, 1536)\n",
      "{'SUBJ': {'devacc': 90.14, 'acc': 89.7, 'ndev': 10000, 'ntest': 10000}}\n",
      "TREC\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(76, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(116, 1536)\n",
      "{'TREC': {'devacc': 77.7, 'acc': 76.0, 'ndev': 5452, 'ntest': 500}}\n",
      "MRPC\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(108, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(108, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(61, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n",
      "(128, 1536)\n"
     ]
    }
   ],
   "source": [
    "tasks = ['CR', 'MR' , 'MPQA', 'SUBJ', 'TREC', 'MRPC','SICKEntailment'] # , 'SICKRelatedness','SICKEntailment', 'STSBenchmark'\n",
    "# 'MR', 'CR',\n",
    "result = []\n",
    "seed = 10 \n",
    "for task in tasks:\n",
    "    print(task)\n",
    "    params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "    params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 256,\n",
    "                                     'tenacity': 5, 'epoch_size': 4,}\n",
    "    params_senteval['embed'] = 'GPT2' # ELMO, GPT2, BERT\n",
    "#     params_senteval['embedPath'] = ''\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # Set up logger\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "    transfer_tasks =    [task]  \n",
    "    results = se.eval(transfer_tasks)\n",
    "    print(results)\n",
    "    result.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CR': {'devacc': 71.87, 'acc': 71.34, 'ndev': 3775, 'ntest': 3775}},\n",
       " {'MR': {'devacc': 72.94, 'acc': 72.12, 'ndev': 10662, 'ntest': 10662}},\n",
       " {'MPQA': {'devacc': 80.82, 'acc': 79.52, 'ndev': 10606, 'ntest': 10606}},\n",
       " {'SUBJ': {'devacc': 87.91, 'acc': 86.97, 'ndev': 10000, 'ntest': 10000}},\n",
       " {'SST2': {'devacc': 73.74, 'acc': 71.5, 'ndev': 872, 'ntest': 1821}},\n",
       " {'TREC': {'devacc': 70.08, 'acc': 67.8, 'ndev': 5452, 'ntest': 500}},\n",
       " {'MRPC': {'devacc': 71.74,\n",
       "   'acc': 67.25,\n",
       "   'f1': 78.06,\n",
       "   'ndev': 4076,\n",
       "   'ntest': 1725}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "batch = ['what are you thinking','how dare you? Mon!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!']\n",
    "bc = BertClient()\n",
    "output = bc.encode(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ['what are you thinking','how!']\n",
    "x,_ = embedding.getElmoEmb(batch);x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ['what are get thinking','how!']\n",
    "x,_ = embedding.getGPT2Emb(batch);x[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
