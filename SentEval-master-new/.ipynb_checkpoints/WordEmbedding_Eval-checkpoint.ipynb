{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0609 04:35:46.375569 140013124196096 deprecation_wrapper.py:119] From /home/rick/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:54: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0609 04:35:46.379127 140013124196096 deprecation_wrapper.py:119] From /home/rick/anaconda3/lib/python3.6/site-packages/tensorflow_hub/__init__.py:65: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "W0609 04:35:49.268437 140013124196096 deprecation_wrapper.py:119] From /home/rick/Xi/WordEmbeddingEval/SentEval-master-new/official/transformer/model/attention_layer.py:24: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "W0609 04:35:49.286476 140013124196096 deprecation_wrapper.py:119] From /home/rick/Xi/WordEmbeddingEval/SentEval-master-new/CNN_Model.py:73: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "import torch\n",
    "import numpy as np\n",
    "import senteval\n",
    "import pickle\n",
    "import copy\n",
    "import operator\n",
    "import embedding\n",
    "import CNN_Model\n",
    "\n",
    "PATH_SENTEVAL = '../'\n",
    "PATH_TO_DATA = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    global model\n",
    "    \n",
    "    for i,sent in enumerate(batch):\n",
    "        if len(sent) == 0:\n",
    "            batch[i] = ['</p>']\n",
    "    if params['embed'] == 'GPT2':\n",
    "        sentences = [' '.join(s) for s in batch] \n",
    "        #output, _ = embedding.getGPT2Emb(batch,True,params[MAX_LENGTH])\n",
    "        output,_ = embedding.getGPT2Emb(sentences,True,max_length)\n",
    "    elif params['embed'] == 'Glove':\n",
    "        output,_ = embedding.getGloveEmb(batch,True,max_length,\"crawl-300d-2M.vec\")\n",
    "    elif  params['embed'] == 'BERT':\n",
    "        sentences = [' '.join(s) for s in batch] \n",
    "        output,_ = embedding.getBertEmb(sentences,True,max_length)\n",
    "    else:\n",
    "        if params['embed'] == 'ELMO':\n",
    "            sentences = [' '.join(s) for s in batch] \n",
    "            output, _ = embedding.getElmoEmb(sentences) \n",
    "            \n",
    "    print(output.shape)\n",
    "    \n",
    "    # Model \n",
    "    if params['modelType'] == 'POI':\n",
    "        output = CNN_Model.POI_Pooling(output)\n",
    "    elif params['modelType'] == 'Transformer':\n",
    "        output = output.astype(np.float32)\n",
    "        output = CNN_Model.getTransformer(params,output)\n",
    "        \n",
    "        print(\"Output from transformer: \",output.shape)\n",
    "        output = CNN_Model.POI_Pooling(output)\n",
    "        print(\"Transformer + POI_Pooling: \",output.shape)\n",
    "    elif params['modelType'] == 'CNN':\n",
    "        output = CNN_Model.getCNNOutput(params,output)\n",
    "    elif params['modelType'] == 'DiaCNN':\n",
    "        output = CNN_Model.getDiaCNNOutput(params,output)\n",
    "    else:\n",
    "        raise(\"Can't not recognoize the model type\")\n",
    "        model = getModel(params,output)\n",
    "        output = model.predict(output)\n",
    "        output = output.reshape(output.shape[0],output.shape[2])\n",
    "        \n",
    "    #print(output.shape)\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR\n",
      "Load embedding\n",
      "crawl-300d-2M.vec\n"
     ]
    }
   ],
   "source": [
    "result = [] \n",
    "seed = 10 \n",
    "max_length = 60 \n",
    "MAX_LENGTH = 'max_length' \n",
    "\n",
    "tasks = ['MR', 'CR','MPQA','SUBJ', 'TREC', 'MRPC','SICKEntailment'] # , 'SICKRelatedness','SICKEntailment', 'STSBenchmark'\n",
    "# \n",
    "result = []\n",
    "seed = 10 \n",
    "for task in tasks:\n",
    "    print(task)\n",
    "    \n",
    "    params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "    params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 256,\n",
    "                                     'tenacity': 5, 'epoch_size': 4,}\n",
    "    \n",
    "    params_senteval['seed'] = seed\n",
    "    params_senteval[MAX_LENGTH] = max_length\n",
    "    params_senteval['embed'] = 'Glove' # 'BERT',  #,'GPT2','Glove','ELMO'\n",
    "    params_senteval['embedPath'] = ''\n",
    "    params_senteval['modelType'] = 'CNN' #['CNN','DiaCNN','POI','Transformer']\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # Set up logger\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "    transfer_tasks =   [task]  \n",
    "    results = se.eval(transfer_tasks)\n",
    "    print(results)\n",
    "    result.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MR': {'devacc': 76.43, 'acc': 75.67, 'ndev': 10662, 'ntest': 10662}},\n",
       " {'CR': {'devacc': 78.32, 'acc': 76.98, 'ndev': 3775, 'ntest': 3775}},\n",
       " {'MPQA': {'devacc': 87.98, 'acc': 87.68, 'ndev': 10606, 'ntest': 10606}},\n",
       " {'SUBJ': {'devacc': 90.52, 'acc': 89.9, 'ndev': 10000, 'ntest': 10000}},\n",
       " {'TREC': {'devacc': 76.1, 'acc': 84.0, 'ndev': 5452, 'ntest': 500}},\n",
       " {'MRPC': {'devacc': 72.33,\n",
       "   'acc': 70.84,\n",
       "   'f1': 80.91,\n",
       "   'ndev': 4076,\n",
       "   'ntest': 1725}},\n",
       " {'SICKEntailment': {'devacc': 78.0,\n",
       "   'acc': 76.09,\n",
       "   'ndev': 500,\n",
       "   'ntest': 4927}},\n",
       " {'SUBJ': {'devacc': 90.52, 'acc': 89.9, 'ndev': 10000, 'ntest': 10000}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
