{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 05:28:35.043094 140258928281344 deprecation_wrapper.py:119] From /home/rick/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:54: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0611 05:28:35.046478 140258928281344 deprecation_wrapper.py:119] From /home/rick/anaconda3/lib/python3.6/site-packages/tensorflow_hub/__init__.py:65: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "W0611 05:28:37.974234 140258928281344 deprecation_wrapper.py:119] From /home/rick/Xi/WordEmbeddingEval/SentEval-master-new/official/transformer/model/attention_layer.py:24: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "W0611 05:28:37.989271 140258928281344 deprecation_wrapper.py:119] From /home/rick/Xi/WordEmbeddingEval/SentEval-master-new/CNN_Model.py:73: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "import torch\n",
    "import numpy as np\n",
    "import senteval\n",
    "import pickle\n",
    "import copy\n",
    "import operator\n",
    "import embedding\n",
    "import CNN_Model\n",
    "\n",
    "PATH_SENTEVAL = '../'\n",
    "PATH_TO_DATA = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    global model\n",
    "    \n",
    "    for i,sent in enumerate(batch):\n",
    "        if len(sent) == 0:\n",
    "            batch[i] = ['</p>']\n",
    "    if params['embed'] == 'GPT2':\n",
    "        sentences = [' '.join(s) for s in batch] \n",
    "        #output, _ = embedding.getGPT2Emb(batch,True,params[MAX_LENGTH])\n",
    "        output,_ = embedding.getGPT2Emb(sentences)\n",
    "    elif params['embed'] == 'Glove':\n",
    "        output,_ = embedding.getGloveEmb(batch,True,-1)\n",
    "    elif  params['embed'] == 'BERT':\n",
    "        sentences = [' '.join(s) for s in batch] \n",
    "        output,_ = embedding.getBertEmb(sentences)\n",
    "    else:\n",
    "        if params['embed'] == 'ELMO':\n",
    "            sentences = [' '.join(s) for s in batch] \n",
    "            output, _ = embedding.getElmoEmb(sentences) \n",
    "            \n",
    "    print(output.shape)\n",
    "    \n",
    "    # Model \n",
    "    if params['modelType'] == 'ROI':\n",
    "        output = CNN_Model.POI_Pooling(output)\n",
    "    elif params['modelType'] == 'Transformer':\n",
    "        output = output.astype(np.float32)\n",
    "        output = CNN_Model.getTransformer(params,output)\n",
    "        \n",
    "        print(\"Output from transformer: \",output.shape)\n",
    "        output = CNN_Model.POI_Pooling(output)\n",
    "        print(\"Transformer + POI_Pooling: \",output.shape)\n",
    "    elif params['modelType'] == 'CNN':\n",
    "        output = CNN_Model.getCNNOutput(params,output)\n",
    "    elif params['modelType'] == 'DiaCNN':\n",
    "        output = CNN_Model.getDiaCNNOutput(params,output)\n",
    "    else:\n",
    "        raise(\"Can't not recognoize the model type\")\n",
    "        model = getModel(params,output)\n",
    "        output = model.predict(output)\n",
    "        output = output.reshape(output.shape[0],output.shape[2])\n",
    "        \n",
    "    #print(output.shape)\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/anaconda3/lib/python3.6/site-packages/bert_serving/client/__init__.py:277: UserWarning: server does not put a restriction on \"max_seq_len\", it will determine \"max_seq_len\" dynamically according to the sequences in the batch. you can restrict the sequence length on the client side for better efficiency\n",
      "  warnings.warn('server does not put a restriction on \"max_seq_len\", '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 31, 768)\n",
      "(128, 27, 768)\n",
      "(128, 29, 768)\n",
      "(128, 30, 768)\n",
      "(128, 35, 768)\n",
      "(128, 36, 768)\n",
      "(128, 36, 768)\n",
      "(128, 39, 768)\n",
      "(128, 37, 768)\n",
      "(128, 38, 768)\n",
      "(128, 38, 768)\n",
      "(128, 36, 768)\n",
      "(128, 40, 768)\n",
      "(128, 41, 768)\n",
      "(128, 40, 768)\n",
      "(128, 42, 768)\n",
      "(128, 45, 768)\n",
      "(128, 46, 768)\n",
      "(128, 50, 768)\n",
      "(128, 44, 768)\n",
      "(128, 44, 768)\n",
      "(128, 42, 768)\n",
      "(128, 47, 768)\n",
      "(128, 50, 768)\n",
      "(128, 46, 768)\n",
      "(128, 50, 768)\n",
      "(128, 49, 768)\n",
      "(128, 57, 768)\n",
      "(128, 55, 768)\n",
      "(128, 56, 768)\n",
      "(128, 59, 768)\n",
      "(108, 57, 768)\n",
      "(128, 39, 768)\n",
      "(128, 29, 768)\n",
      "(128, 38, 768)\n",
      "(128, 37, 768)\n",
      "(128, 40, 768)\n",
      "(128, 38, 768)\n",
      "(128, 33, 768)\n",
      "(128, 45, 768)\n",
      "(128, 40, 768)\n",
      "(128, 42, 768)\n",
      "(128, 40, 768)\n",
      "(128, 47, 768)\n",
      "(128, 42, 768)\n",
      "(128, 44, 768)\n",
      "(128, 40, 768)\n",
      "(128, 52, 768)\n",
      "(128, 52, 768)\n",
      "(128, 58, 768)\n",
      "(128, 56, 768)\n",
      "(128, 47, 768)\n",
      "(128, 51, 768)\n",
      "(128, 44, 768)\n",
      "(128, 53, 768)\n",
      "(128, 51, 768)\n",
      "(128, 47, 768)\n",
      "(128, 54, 768)\n",
      "(128, 52, 768)\n",
      "(128, 54, 768)\n",
      "(128, 49, 768)\n",
      "(128, 60, 768)\n",
      "(128, 57, 768)\n",
      "(108, 57, 768)\n",
      "(128, 28, 768)\n",
      "(128, 31, 768)\n",
      "(128, 33, 768)\n",
      "(128, 37, 768)\n",
      "(128, 38, 768)\n",
      "(128, 42, 768)\n",
      "(128, 39, 768)\n",
      "(128, 42, 768)\n",
      "(128, 51, 768)\n",
      "(128, 52, 768)\n",
      "(128, 47, 768)\n",
      "(128, 52, 768)\n",
      "(128, 53, 768)\n",
      "(61, 54, 768)\n",
      "(128, 33, 768)\n",
      "(128, 37, 768)\n",
      "(128, 48, 768)\n",
      "(128, 45, 768)\n",
      "(128, 43, 768)\n",
      "(128, 56, 768)\n",
      "(128, 49, 768)\n",
      "(128, 51, 768)\n",
      "(128, 54, 768)\n",
      "(128, 52, 768)\n",
      "(128, 49, 768)\n",
      "(128, 49, 768)\n",
      "(128, 57, 768)\n",
      "(61, 53, 768)\n",
      "{'MRPC': {'devacc': 73.51, 'acc': 69.1, 'f1': 77.75, 'ndev': 4076, 'ntest': 1725}}\n"
     ]
    }
   ],
   "source": [
    "result = [] \n",
    "seed = 10 \n",
    "max_length = 60 \n",
    "MAX_LENGTH = 'max_length' \n",
    "\n",
    "tasks = ['MRPC' ] # , 'SICKRelatedness','SICKEntailment', 'STSBenchmark'\n",
    "# 'MR', 'CR','MPQA','SUBJ','TREC', 'MRPC','SICKEntailment'\n",
    "result = []\n",
    "seed = 10 \n",
    "for task in tasks:\n",
    "    print(task)\n",
    "    \n",
    "    params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "    params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 256,\n",
    "                                     'tenacity': 5, 'epoch_size': 4,}\n",
    "    \n",
    "    params_senteval['seed'] = seed\n",
    "    params_senteval[MAX_LENGTH] = max_length\n",
    "    params_senteval['embed'] = 'BERT' # 'BERT',  #,'GPT2','Glove','ELMO'\n",
    "    params_senteval['embedPath'] = ''\n",
    "    params_senteval['modelType'] = 'ROI' #['CNN','DiaCNN','POI','Transformer']\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # Set up logger\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "    transfer_tasks =   [task]  \n",
    "    results = se.eval(transfer_tasks)\n",
    "    print(results)\n",
    "    result.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'TREC': {'devacc': 63.99, 'acc': 72.6, 'ndev': 5452, 'ntest': 500}},\n",
       " {'MRPC': {'devacc': 70.9,\n",
       "   'acc': 69.04,\n",
       "   'f1': 80.51,\n",
       "   'ndev': 4076,\n",
       "   'ntest': 1725}},\n",
       " {'SICKEntailment': {'devacc': 70.2,\n",
       "   'acc': 68.74,\n",
       "   'ndev': 500,\n",
       "   'ntest': 4927}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
