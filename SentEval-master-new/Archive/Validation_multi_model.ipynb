{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import Model\n",
    "import numpy as np \n",
    "#import preTool\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import senteval\n",
    "import pickle\n",
    "import copy\n",
    "import operator\n",
    "\n",
    "PATH_SENTEVAL = '../'\n",
    "PATH_TO_DATA = 'data'\n",
    "\n",
    "maxLength = 30    \n",
    "wordDim = 300    # 300 \n",
    "num_neurons = [600,600]   # [600,600f]\n",
    "extractLayer = ['X_input_second','X_input_mask_2']\n",
    "kernel_reg = 0.001\n",
    "batch_size = 400\n",
    "merge_mode = 'concat'\n",
    "checkpoint = [ \"../Checkpoint_summary/Fre_2500-loss-1.3988-cata_acc-0.7049-val_loss-1.5115-cate_acc_val-0.6838_.hdf5\"  ]# Change \n",
    "embeddingPath = \"../Embedding/word2vec.810B.300d.txt\"  # Change \n",
    "processedPath = \"../processed/\"\n",
    "tokenizerFile = 'tokenizer.txt'\n",
    "embeddingFile =  'embedding_matrix.txt'\n",
    "dicFile = 'wordDic.txt'\n",
    "marked_token = \"maskedtoken\"\n",
    "trainable = True\n",
    "\n",
    "model = []\n",
    "\n",
    "\n",
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    sentences = [' '.join(s) for s in batch]\n",
    "    \n",
    "    with open(processedPath + tokenizerFile , \"rb\") as input_file:\n",
    "        t = pickle.load(input_file)\n",
    "    \n",
    "    with open(processedPath + embeddingFile , \"rb\") as input_file:\n",
    "        embedding_matrix = pickle.load(input_file)\n",
    "  \n",
    "    with open(processedPath + dicFile , \"rb\") as input_file:\n",
    "        wholeVocab = pickle.load(input_file) \n",
    "\n",
    "    #embedding_matrix = np.zeros([49985,wordDim])\n",
    "        \n",
    "    sentences  = Model.preprocessing(sentences)\n",
    "    sentences = t.texts_to_sequences(sentences)\n",
    "    sentences = pad_sequences(sentences, maxlen=maxLength, padding='post')\n",
    "    \n",
    "    if len(model) == 0 :\n",
    "        \n",
    "        for weight in checkpoint:\n",
    "            model_x = Model.buildModel(sentences,kernel_reg,num_neurons,merge_mode, 678318,maxLength, wordDim,np.zeros([678318,300]),trainable)\n",
    "            print(\"load weights\")\n",
    "            model_x.load_weights(weight)\n",
    "            model.append(model_x)\n",
    "\n",
    "    output = []\n",
    "    for i in model:\n",
    "        output_x = Model.extractHiddenState(extractLayer,i,sentences)\n",
    "#        \n",
    "        output_x = np.concatenate((output_x[0],output_x[1]),axis=1)\n",
    "        output.append(output_x)\n",
    "    \n",
    "    if len(output) == 2:\n",
    "        print(\"combine two model results\")\n",
    "        output = np.concatenate((output[0],output[1]),axis = 1)\n",
    "        \n",
    "    elif len(output) == 3:\n",
    "        print(\"combine three model results\")\n",
    "        output_temp = np.concatenate(output[0],output[1],axis = 1)\n",
    "        output = np.concatenate((output[2],output_temp),axis = 1)\n",
    "    \n",
    "    else: \n",
    "        print(\"Single model results\")\n",
    "        output = output[0]\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 215,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "# Set up logger\n",
    "se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "transfer_tasks = ['CR','TREC']\n",
    "# 'MR', 'CR' ,'MPQA', 'SUBJ','TREC', 'MRPC','SICKEntailment', 'SICKRelatedness'  ,'TREC','MRPC'\n",
    "results = se.eval(transfer_tasks)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CR': {'devacc': 76.55, 'acc': 75.5, 'ndev': 3775, 'ntest': 3775},\n",
       " 'TREC': {'devacc': 77.2, 'acc': 79.2, 'ndev': 5452, 'ntest': 500}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
