{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import Model\n",
    "import numpy as np \n",
    "\n",
    "import senteval\n",
    "import pickle\n",
    "\n",
    "\n",
    "PATH_SENTEVAL = '../'\n",
    "PATH_TO_DATA = 'data'\n",
    "\n",
    "maxLength = 30    \n",
    "wordDim = 300    # 300 \n",
    "num_neurons = [2*wordDim,2*wordDim]   # [600,600f]\n",
    "extractLayer = ['X_input_second','X_input_mask_2']\n",
    "kernel_reg = 0.001\n",
    "batch_size = 400\n",
    "merge_mode = 'concat'\n",
    "\n",
    "# _weights-epoch-01-loss-7.0428-val_loss-8.5336.hdf5,  _weights-epoch-01-loss-9.0715-val_loss-8.6046.hdf5\n",
    "checkpoint = \"../checkpoint_mask_2500_MSE/loss-0.1413-cata_acc-0.7126-val_loss-0.1590-cate_acc_val-0.6665.hdf5\"  # Change \n",
    "processedPath = \"../processed/\"\n",
    "tokenizerFile = 'tokenizer.txt'\n",
    "embeddingFile =  'embedding_matrix.txt'\n",
    "embeddingSize = 678350\n",
    "\n",
    "with open(processedPath + tokenizerFile , \"rb\") as input_file:\n",
    "    t = pickle.load(input_file)\n",
    "\n",
    "with open(processedPath + embeddingFile , \"rb\") as input_file:\n",
    "    embedding_matrix = pickle.load(input_file) \n",
    "    \n",
    "vocab_size = len(embedding_matrix)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    global count\n",
    "    global t\n",
    "    global embedding_matrix\n",
    "    global model \n",
    "    sentences = [' '.join(s) for s in batch]\n",
    "    \n",
    "    # Preprocessing\n",
    "    sentences = Model.preprocessing(sentences)\n",
    "    sentences = t.texts_to_sequences(sentences)\n",
    "    sentences = pad_sequences(sentences, maxlen=maxLength, padding='post')\n",
    "    # Restore model \n",
    "    \n",
    "    if count == 0:\n",
    "        print(\"build model\")\n",
    "        model = Model.buildModel(sentences,kernel_reg,num_neurons,merge_mode, embeddingSize,maxLength, wordDim,np.zeros([embeddingSize,wordDim]),False)\n",
    "        model.load_weights(checkpoint)\n",
    "        count += 1\n",
    "\n",
    "    # Extract th output \n",
    "    output = Model.extractHiddenState(extractLayer,model,sentences)\n",
    "    output = np.concatenate((output[0],output[1]),axis=1)\n",
    "    \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR\n",
      "Pre processing Data\n",
      "build model\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "SUBJ\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "CR\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "MPQA\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n",
      "Pre processing Data\n"
     ]
    }
   ],
   "source": [
    "tasks = ['MR', 'SUBJ','CR','MPQA','TREC','MRPC']\n",
    "result = []\n",
    "for task in tasks:\n",
    "    print(task)\n",
    "    params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "    params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 512,\n",
    "                                     'tenacity': 5, 'epoch_size': 5}\n",
    "    # Set up logger\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "    transfer_tasks =    [task]  # ['CR','MPQA','TREC','MRPC']\n",
    "    # 'MR', 'CR' ,'MPQA', 'SUBJ','TREC', 'MRPC','SICKEntailment', 'SICKRelatedness'  ,'TREC','MRPC'\n",
    "    results = se.eval(transfer_tasks)\n",
    "    result.append(results)\n",
    "    \n",
    "# params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "# params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 512,\n",
    "#                                  'tenacity': 5, 'epoch_size': 10}\n",
    "# # Set up logger\n",
    "# se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "# transfer_tasks = ['MR', 'SUBJ','CR','MPQA','TREC','MRPC']\n",
    "\n",
    "# # 'MR', 'CR' ,'MPQA', 'SUBJ','TREC', 'MRPC','SICKEntailment', 'SICKRelatedness'\n",
    "# results = se.eval(transfer_tasks)\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MR': {'devacc': 73.69, 'acc': 72.94, 'ndev': 10662, 'ntest': 10662}},\n",
       " {'SUBJ': {'devacc': 90.1, 'acc': 89.73, 'ndev': 10000, 'ntest': 10000}},\n",
       " {'CR': {'devacc': 77.86, 'acc': 76.45, 'ndev': 3775, 'ntest': 3775}},\n",
       " {'MPQA': {'devacc': 84.98, 'acc': 84.6, 'ndev': 10606, 'ntest': 10606}},\n",
       " {'TREC': {'devacc': 77.57, 'acc': 80.4, 'ndev': 5452, 'ntest': 500}},\n",
       " {'MRPC': {'devacc': 73.92,\n",
       "   'acc': 73.45,\n",
       "   'f1': 81.58,\n",
       "   'ndev': 4076,\n",
       "   'ntest': 1725}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
