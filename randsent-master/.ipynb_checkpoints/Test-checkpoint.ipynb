{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenxi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0429 17:37:25.279419 4795069888 deprecation_wrapper.py:119] From /Users/chenxi/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:54: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0429 17:37:25.283461 4795069888 deprecation_wrapper.py:119] From /Users/chenxi/anaconda3/lib/python3.6/site-packages/tensorflow_hub/__init__.py:65: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from models import BOREP, ESN, RandLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    words = set([])\n",
    "    for l in samples:\n",
    "        for w in l:\n",
    "            if w not in words:\n",
    "                words.add(w)\n",
    "    word2id = {w:i for i, w in enumerate(['<p>'] + list(words))}\n",
    "    params.word2id = word2id\n",
    "    params.lut = utils.load_vecs(params, word2id, zero=params.zero)\n",
    "    if params.random_word_embeddings:\n",
    "        utils.init_word_embeds(params.lut, params)\n",
    "    return params\n",
    "\n",
    "def batcher(params, batch):\n",
    "#     for i in batch:\n",
    "#         print(len(i))\n",
    "    network = params['network']\n",
    "    for n,i in enumerate(batch):\n",
    "        if len(i) == 0:\n",
    "            batch[n] = ['<p>']\n",
    "    with torch.no_grad():\n",
    "        vec = network.encode(batch, params)\n",
    "    return vec\n",
    "\n",
    "def get_results(params, seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if params.gpu:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    network = None\n",
    "    if params.model == \"borep\":\n",
    "        network = BOREP(params)\n",
    "    elif params.model == \"lstm\":\n",
    "        network = RandLSTM(params)\n",
    "    elif params.model == \"esn\":\n",
    "        network = ESN(params)\n",
    "\n",
    "    se = senteval.engine.SE({\n",
    "        'task_path': os.path.join(params.senteval_path, 'data'),\n",
    "        'word_emb_file': params.word_emb_file, 'word_emb_dim': params.word_emb_dim,\n",
    "        'usepytorch': True, 'kfold': params.n_folds, 'feat_dim': senteval_feat_dim,\n",
    "        'random_word_embeddings': params.random_word_embeddings, 'seed': seed,\n",
    "        'batch_size': params.se_batch_size, 'network': network\n",
    "    }, batcher, prepare)\n",
    "\n",
    "    if params.task_type == \"downstream\":\n",
    "        results = se.eval(['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC', 'MRPC', 'SICKRelatedness',\n",
    "                           'SICKEntailment', 'STSBenchmark'])\n",
    "    else:\n",
    "        results = se.eval(\n",
    "            ['Length', 'WordContent', 'Depth', 'TopConstituents', 'BigramShift', 'Tense',\n",
    "             'SubjNumber', 'ObjNumber', 'OddManOut', 'CoordinationInversion'])\n",
    "    return results\n",
    "\n",
    "def consolidate(results, total_results):\n",
    "    new_r = {}\n",
    "    for task, result in results.items():\n",
    "        if 'devacc' in result:\n",
    "            dev, test = result['devacc'], result['acc']\n",
    "            new_r[task] = (dev, test)\n",
    "        elif 'devpearson' in result:\n",
    "            dev, test = result['devpearson'], result['pearson']\n",
    "            dev = dev if not np.isnan(dev) else 0.\n",
    "            test = test if not np.isnan(test) else 0.\n",
    "            new_r[task] = (dev*100, test*100)\n",
    "    for task in new_r:\n",
    "        if task not in total_results:\n",
    "            total_results[task] = []\n",
    "        total_results[task].append(new_r[task])\n",
    "    return total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chenxi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py -f /Users/chenxi/Library/Jupyter/runtime/kernel-32cfd062-71ac-4363-ad08-ea3ceb42fb8d.json\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"RandSent - Random Sentence Representations\")\n",
    "\n",
    "parser.add_argument(\"--model\",\n",
    "            help=\"Type of model to use (either borep, esn, or lstm, default borep).\",\n",
    "                    choices=[\"borep\",\"esn\", \"lstm\"], default=\"lstm\")\n",
    "parser.add_argument(\"--task_type\",\n",
    "            help=\"Type of task to try (either downstream or probing, default downstream).\",\n",
    "                    choices=[\"downstream\", \"probing\"], default=\"downstream\")\n",
    "parser.add_argument(\"--n_folds\", type=int,\n",
    "            help=\"Number of folds for cross-validation in SentEval (default 10).\", default=10)\n",
    "parser.add_argument(\"--se_batch_size\", type=int,\n",
    "            help=\"Batch size for embedding sentences in SentEval (default 16).\", default=8)\n",
    "parser.add_argument(\"--gpu\", type=int, choices=[0,1],\n",
    "            help=\"Whether to use GPU (default 0).\", default=0)\n",
    "parser.add_argument(\"--senteval_path\", type=str,\n",
    "            help=\"Path to SentEval (default ./SentEval).\", default=\"./SentEval\")\n",
    "parser.add_argument(\"--word_emb_file\", type=str,\n",
    "            help=\"Path to word embeddings file (default glove.6B.300d.txt).\", \n",
    "                    default=\"glove.6B.300d.txt\")\n",
    "parser.add_argument(\"--word_emb_dim\", type=int,\n",
    "            help=\"Dimension of word embeddings (default 300).\", default=300)\n",
    "\n",
    "#Network parameters\n",
    "parser.add_argument(\"--input_dim\", type=int, default=300,\n",
    "            help=\"Output feature dimensionality (default 300).\")\n",
    "parser.add_argument(\"--output_dim\", type=int, default=4096,\n",
    "            help=\"Output feature dimensionality (default 4096).\")\n",
    "parser.add_argument(\"--max_seq_len\", type=int, default=96,\n",
    "            help=\"Sequence length (default 96).\")\n",
    "parser.add_argument(\"--bidirectional\", type=int, choices=[0,1], default=1,\n",
    "            help=\"Whether to be bidirectional (default 1).\")\n",
    "parser.add_argument(\"--init\", type=str, choices=[\"none\", \"orthogonal\", \"sparse\", \"normal\",\n",
    "                                                 \"uniform\", \"kaiming\", \"xavier\"],\n",
    "            help=\"Type of initialization to use (either none, orthogonal, sparse, normal, uniform, kaiming, \"\n",
    "                 \"or xavier, default none).\", default=\"uniform\")\n",
    "parser.add_argument(\"--activation\", type=str,\n",
    "                    help=\"Activation function to apply to features (default none).\", default=None)\n",
    "parser.add_argument(\"--pooling\", choices=[\"min\", \"max\", \"mean\", \"hier\", \"sum\"],\n",
    "            help=\"Type of pooling (either min, max, mean, hier, or sum, default max).\", default=\"max\")\n",
    "\n",
    "#Embedding parameters\n",
    "parser.add_argument(\"--zero\", type=int, choices=[0,1],\n",
    "            help=\"Whether to initialize word embeddings to zero (default 1).\", default=1)\n",
    "parser.add_argument(\"--pos_enc\", type=int, choices=[0,1], default=0,\n",
    "            help=\"Whether to do positional encoding (default 0).\")\n",
    "parser.add_argument(\"--pos_enc_concat\", type=int, choices=[0,1],\n",
    "                    help=\"Whether to concat positional encoding to regular embedding (default 0).\", default=0)\n",
    "parser.add_argument(\"--random_word_embeddings\", type=int, choices=[0,1],\n",
    "            help=\"Whether to load pretrained embeddings (default 0).\", default=0)\n",
    "\n",
    "#Projection parameters\n",
    "parser.add_argument(\"--projection\", type=str, choices=[\"none\", \"same\"],\n",
    "            help=\"Type of projection (either none or same, default same).\", default=\"same\")\n",
    "#ESN parameters\n",
    "parser.add_argument(\"--spectral_radius\", type=float,\n",
    "            help=\"Spectral radius for ESN (default 1.).\", default=1.)\n",
    "parser.add_argument(\"--leaky\", type=float,\n",
    "            help=\"Fraction of previous state to leak for ESN (default 0).\", default=0)\n",
    "parser.add_argument(\"--concat_inp\", type=int, choices=[0,1],\n",
    "            help=\"Whether to concatenate input to hidden state for ESN (default 0).\", default=0)\n",
    "parser.add_argument(\"--stdv\", type=float,\n",
    "            help=\"Width of uniform interval to sample weights for ESN (default 1).\", default=1.)\n",
    "parser.add_argument(\"--sparsity\", type=float,\n",
    "            help=\"Sparsity of recurrent weights for ESN (default 0).\", default=0)\n",
    "\n",
    "#LSTM parameters\n",
    "parser.add_argument(\"--num_layers\", type=int,\n",
    "                    help=\"Number of layers for random LSTM (default 1).\", default=1)\n",
    "\n",
    "\n",
    "\n",
    "print(\" \".join(sys.argv))\n",
    "\n",
    "paras = parser.parse_known_args()\n",
    "params, remaining_args = parser.parse_known_args()\n",
    "\n",
    "# assert remaining_args == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glove.6B.300d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-121daa6e1732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtotal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtotal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-057c90b122d7>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(params, seed)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"downstream\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         results = se.eval(['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC', 'MRPC', 'SICKRelatedness',\n\u001b[0;32m---> 49\u001b[0;31m                            'SICKEntailment', 'STSBenchmark'])\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         results = se.eval(\n",
      "\u001b[0;32m~/Desktop/Thesis/Code/WordEmbeddingEval/randsent-master/SentEval/senteval/engine.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis/Code/WordEmbeddingEval/randsent-master/SentEval/senteval/engine.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis/Code/WordEmbeddingEval/randsent-master/SentEval/senteval/engine.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis/Code/WordEmbeddingEval/randsent-master/SentEval/senteval/binary.py\u001b[0m in \u001b[0;36mdo_prepare\u001b[0;34m(self, params, prepare)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# prepare is given the whole text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# prepare puts everything it outputs in \"params\" : params.word2id etc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Those output will be further used by \"batcher\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-057c90b122d7>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(params, samples)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mword2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<p>'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_word_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_word_embeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis/Code/WordEmbeddingEval/randsent-master/utils.py\u001b[0m in \u001b[0;36mload_vecs\u001b[0;34m(params, word2id, zero)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mn_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0membedding_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.6B.300d.txt'"
     ]
    }
   ],
   "source": [
    "senteval_feat_dim = params.output_dim if not params.bidirectional else 2*params.output_dim\n",
    "\n",
    "# params.activation = eval(params.activation)() if \\\n",
    "#         (params.activation is not None and eval(params.activation) is not None) \\\n",
    "#         else None\n",
    "\n",
    "if params.pos_enc_concat:\n",
    "    params.input_dim *= 2\n",
    "if params.concat_inp:\n",
    "    senteval_feat_dim += params.input_dim\n",
    "\n",
    "sys.path.insert(0, params.senteval_path)\n",
    "import senteval\n",
    "\n",
    "seeds = [10, 100, 1000, 10000, 100000]\n",
    "total_results = {}\n",
    "for seed in seeds:\n",
    "    results = get_results(params, seed)\n",
    "    total_results = consolidate(results, total_results)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "for task, result in total_results.items():\n",
    "    dev = [i[0] for i in result]\n",
    "    test = [i[1] for i in result]\n",
    "    print(\"{0} | {1:0.2f} {2:0.2f} | {3:0.2f} {4:0.2f}\".format(task, np.mean(dev), np.std(dev),\n",
    "                                                          np.mean(test), np.std(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "if a ==0 and a!=0:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(4):\n",
    "    x.append([2,3,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "type(x),type(x[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
